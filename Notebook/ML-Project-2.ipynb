{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f663760-f093-4897-b883-d606be7facb2",
   "metadata": {},
   "source": [
    "# ML-Project-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82628d-f13a-41b3-95ad-54108915a3db",
   "metadata": {},
   "source": [
    "## This project extends my chatbot demo by integrating it with the Endor AI platform for advanced dynamic learning and predictive modeling. The codebase is designed to be a reference implementation for deploying the chatbot on Endor, demonstrating how to preprocess text data, train a predictive model, implement adaptive conversation flows, and integrate everything into a Flask web application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc3d23-130a-4954-bb06-d8791f138cbd",
   "metadata": {},
   "source": [
    "### Step 1 - Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b4263a-580a-4c16-b933-cf578b77c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.11/site-packages (2.2.5)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Collecting transitions\n",
      "  Downloading transitions-0.9.2-py2.py3-none-any.whl.metadata (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in /opt/anaconda3/lib/python3.11/site-packages (from flask) (8.1.7)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from transitions) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.0->flask) (2.1.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transitions-0.9.2-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.2/774.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cymem, wasabi, transitions, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 transitions-0.9.2 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests flask spacy nltk transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9ad6a-a0e3-4e1a-bbe3-0f6a770d922a",
   "metadata": {},
   "source": [
    "### Step 2 - Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d732e4-3399-4e80-8d74-b99972b22c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "    # Extract part-of-speech tags, named entities, etc.\n",
    "    features = {\n",
    "        \"num_tokens\": len(doc),\n",
    "        \"entities\": [ent.label_ for ent in doc.ents],\n",
    "        # More features can be added as needed\n",
    "    }\n",
    "    return features\n",
    "\n",
    "sample_text = \"I am happy with the service, but could be better.\"\n",
    "print(extract_features(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ca41c-20e0-43c1-bd1a-7265e4819dd8",
   "metadata": {},
   "source": [
    "## ** Formatting Data for Endor **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224acb24-837e-4cef-8d8e-2178893c59c9",
   "metadata": {},
   "source": [
    "### Combine structured and unstructured features into a JSON (or other required format) that matches Endor’s API specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209c3be-2432-4ecd-8929-511174881929",
   "metadata": {},
   "source": [
    "### Step 3 - Training the Predictive Model with Endor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190011b-a33a-424b-aef9-75930d5f05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your actual Endor API endpoint and key\n",
    "ENDOR_API_URL = \"https://api.endor.com/v1/train\"\n",
    "API_KEY = \"your_api_key_here\"\n",
    "\n",
    "def train_model(training_data):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "    response = requests.post(ENDOR_API_URL, headers=headers, json=training_data)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Model training initiated successfully!\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error during training:\", response.text)\n",
    "        return None\n",
    "\n",
    "# Example training data format (structure depends on Endor's API)\n",
    "training_data = {\n",
    "    \"data\": [\n",
    "        # Your data entries here, combining structured fields and NLP-extracted features\n",
    "    ],\n",
    "    \"target\": \"desired_outcome\"\n",
    "}\n",
    "\n",
    "train_model(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10037997-e831-474d-a578-53c02832a332",
   "metadata": {},
   "source": [
    "### Step 4 - Building Adaptive Conversation Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfa38f-e10e-4e60-981b-ad0e8102298f",
   "metadata": {},
   "source": [
    "### Implement State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2870888-0d7d-4787-a118-15b121232f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transitions import Machine\n",
    "\n",
    "class Chatbot:\n",
    "    states = ['greeting', 'query_handling', 'escalation', 'farewell']\n",
    "\n",
    "    def __init__(self):\n",
    "        self.machine = Machine(model=self, states=Chatbot.states, initial='greeting')\n",
    "        self.machine.add_transition(trigger='process_query', source='greeting', dest='query_handling')\n",
    "        self.machine.add_transition(trigger='escalate', source='query_handling', dest='escalation')\n",
    "        self.machine.add_transition(trigger='finish', source='*', dest='farewell')\n",
    "\n",
    "    def current_state(self):\n",
    "        return self.state\n",
    "\n",
    "bot = Chatbot()\n",
    "print(\"Initial state:\", bot.current_state())\n",
    "bot.process_query()\n",
    "print(\"State after processing query:\", bot.current_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cc5ae-7e3f-4f83-8eca-99eac2297aef",
   "metadata": {},
   "source": [
    "### Step 5 - Dynamic Adaptation Based on Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ae969-0e41-4189-9cd4-cc3373111d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(user_input):\n",
    "    # Preprocess the input as needed (e.g., extract features)\n",
    "    features = extract_features(user_input)\n",
    "    # Prepare the payload for Endor API\n",
    "    payload = {\n",
    "        \"features\": features,\n",
    "        # Other required fields per Endor’s API\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "    prediction_url = \"https://api.endor.com/v1/predict\"\n",
    "    response = requests.post(prediction_url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Assuming this returns the prediction outcome\n",
    "    else:\n",
    "        print(\"Error during prediction:\", response.text)\n",
    "        return None\n",
    "\n",
    "# Example usage within a conversation flow\n",
    "user_input = \"I am not satisfied with my recent experience.\"\n",
    "prediction = get_prediction(user_input)\n",
    "if prediction:\n",
    "    # Decide based on prediction result\n",
    "    if prediction.get(\"sentiment\") == \"negative\":\n",
    "        bot.escalate()\n",
    "        response_text = \"I understand your concern. Let me connect you with our support team.\"\n",
    "    else:\n",
    "        bot.process_query()\n",
    "        response_text = \"Thanks for your feedback! How can I assist you further?\"\n",
    "else:\n",
    "    response_text = \"I'm having trouble understanding that. Could you please rephrase?\"\n",
    "\n",
    "print(\"Bot response:\", response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d81534-8bb6-4de0-b94b-1cb3bee832cb",
   "metadata": {},
   "source": [
    "### Step 6 - Integrating Everything into a Flask Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436c12f-d041-4317-8c0f-8bb24dbd395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "chatbot_instance = Chatbot()\n",
    "\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    user_message = request.json.get(\"message\", \"\")\n",
    "    # Get prediction from Endor\n",
    "    prediction = get_prediction(user_message)\n",
    "    \n",
    "    # Determine response based on prediction\n",
    "    if prediction and prediction.get(\"sentiment\") == \"negative\":\n",
    "        chatbot_instance.escalate()\n",
    "        reply = \"I’m sorry to hear that. Let me connect you with a support specialist.\"\n",
    "    else:\n",
    "        chatbot_instance.process_query()\n",
    "        reply = \"Thanks for sharing that. What else can I help you with?\"\n",
    "    \n",
    "    return jsonify({\"reply\": reply, \"state\": chatbot_instance.current_state()})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
